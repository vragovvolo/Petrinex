{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Comprehensive Data Processing Pipeline\n",
    "\n",
    "This notebook consolidates ALL data processing required before forecasting:\n",
    "\n",
    "1. **Schema-Enforced Ingestion**: Read CSV files with proper Spark schemas\n",
    "2. **Bronze Layer Creation**: Clean and standardize data with type conversion\n",
    "3. **Data Quality Validation**: Comprehensive validation highlighting problematic rows\n",
    "4. **Silver Layer Creation**: Enhanced data with metadata and quality scores\n",
    "5. **Forecasting Preparation**: Prepare clean, validated data for forecasting workflows\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Proper Spark Schemas**: Enforced data types and constraints for bronze/silver tables\n",
    "- **Data Validation**: Highlights source files and specific rows with issues  \n",
    "- **Quality Scoring**: Each row gets a data quality score for filtering\n",
    "- **Comprehensive Reporting**: Detailed processing and validation reports\n",
    "- **Modular Design**: Functions can be reused across different workflows\n",
    "\n",
    "This replaces the previous scattered processing logic and provides a single source of truth for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from databricks.connect import DatabricksSession as SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "\n",
    "from petrinex.config import load_config\n",
    "from petrinex.process import (\n",
    "    process_csvs_to_bronze_and_silver,\n",
    "    prepare_data_for_forecasting\n",
    ")\n",
    "from petrinex.schemas import get_schema, get_validation_rules\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "config = load_config(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 1: Process Conventional Volume Data (CSV -> Bronze -> Silver)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 1: Processing Conventional Volume Data\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    conv_bronze_df, conv_silver_df, conv_report = process_csvs_to_bronze_and_silver(\n",
    "        config=config,\n",
    "        dataset='conventional',\n",
    "        spark=spark,\n",
    "        validate_data=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Conventional Volume Processing Complete!\")\n",
    "    print(f\"   Bronze rows: {conv_report['row_counts'].get('bronze', 0):,}\")\n",
    "    print(f\"   Silver rows: {conv_report['row_counts'].get('silver', 0):,}\")\n",
    "    print(f\"   Quality: {conv_report['data_quality_summary'].get('quality_assessment', 'N/A')}\")\n",
    "    \n",
    "    if conv_report.get('validation_report'):\n",
    "        val_report = conv_report['validation_report']\n",
    "        print(f\"   Validation errors: {len(val_report.get('validation_errors', []))}\")\n",
    "        print(f\"   Validation warnings: {len(val_report.get('validation_warnings', []))}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing conventional volume data: {e}\")\n",
    "    conv_bronze_df = None\n",
    "    conv_silver_df = None\n",
    "    conv_report = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 2: Process NGL Volume Data (CSV -> Bronze -> Silver)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 2: Processing NGL Volume Data\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    ngl_bronze_df, ngl_silver_df, ngl_report = process_csvs_to_bronze_and_silver(\n",
    "        config=config,\n",
    "        dataset='ngl',\n",
    "        spark=spark,\n",
    "        validate_data=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ NGL Volume Processing Complete!\")\n",
    "    print(f\"   Bronze rows: {ngl_report['row_counts'].get('bronze', 0):,}\")\n",
    "    print(f\"   Silver rows: {ngl_report['row_counts'].get('silver', 0):,}\")\n",
    "    print(f\"   Quality: {ngl_report['data_quality_summary'].get('quality_assessment', 'N/A')}\")\n",
    "    \n",
    "    if ngl_report.get('validation_report'):\n",
    "        val_report = ngl_report['validation_report']\n",
    "        print(f\"   Validation errors: {len(val_report.get('validation_errors', []))}\")\n",
    "        print(f\"   Validation warnings: {len(val_report.get('validation_warnings', []))}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing NGL volume data: {e}\")\n",
    "    ngl_bronze_df = None\n",
    "    ngl_silver_df = None\n",
    "    ngl_report = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 3: Data Quality Analysis and Reporting\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 3: Data Quality Analysis\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def print_validation_details(report, dataset_name):\n",
    "    \"\"\"Print detailed validation report.\"\"\"\n",
    "    if not report or not report.get('validation_report'):\n",
    "        print(f\"   No validation report available for {dataset_name}\")\n",
    "        return\n",
    "    \n",
    "    val_report = report['validation_report']\n",
    "    \n",
    "    print(f\"\\nüîç {dataset_name.upper()} Validation Details:\")\n",
    "    print(f\"   Total rows processed: {val_report.get('total_rows', 0):,}\")\n",
    "    \n",
    "    # Print errors\n",
    "    errors = val_report.get('validation_errors', [])\n",
    "    if errors:\n",
    "        print(f\"   ‚ùå {len(errors)} ERRORS found:\")\n",
    "        for i, error in enumerate(errors[:5], 1):  # Show first 5 errors\n",
    "            print(f\"      {i}. {error}\")\n",
    "        if len(errors) > 5:\n",
    "            print(f\"      ... and {len(errors) - 5} more errors\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No validation errors found\")\n",
    "    \n",
    "    # Print warnings\n",
    "    warnings = val_report.get('validation_warnings', [])\n",
    "    if warnings:\n",
    "        print(f\"   ‚ö†Ô∏è  {len(warnings)} WARNINGS found:\")\n",
    "        for i, warning in enumerate(warnings[:5], 1):  # Show first 5 warnings\n",
    "            print(f\"      {i}. {warning}\")\n",
    "        if len(warnings) > 5:\n",
    "            print(f\"      ... and {len(warnings) - 5} more warnings\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No validation warnings found\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Print detailed validation reports\n",
    "if conv_report:\n",
    "    print_validation_details(conv_report, \"Conventional Volume\")\n",
    "\n",
    "if ngl_report:\n",
    "    print_validation_details(ngl_report, \"NGL Volume\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 4: Schema Validation and Verification\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 4: Schema Validation and Verification\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def verify_table_schema(df, table_type, layer):\n",
    "    \"\"\"Verify that the DataFrame matches expected schema.\"\"\"\n",
    "    if df is None:\n",
    "        print(f\"   ‚ùå {table_type} {layer} DataFrame is None\")\n",
    "        return False\n",
    "    \n",
    "    expected_schema = get_schema(table_type, layer)\n",
    "    expected_columns = {field.name for field in expected_schema.fields}\n",
    "    actual_columns = set(df.columns)\n",
    "    \n",
    "    missing_columns = expected_columns - actual_columns\n",
    "    extra_columns = actual_columns - expected_columns\n",
    "    \n",
    "    print(f\"\\nüîç {table_type.upper()} {layer.upper()} Schema Verification:\")\n",
    "    print(f\"   Expected columns: {len(expected_columns)}\")\n",
    "    print(f\"   Actual columns: {len(actual_columns)}\")\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"   ‚ùå Missing columns: {missing_columns}\")\n",
    "    \n",
    "    if extra_columns:\n",
    "        print(f\"   ‚ÑπÔ∏è  Extra columns: {extra_columns}\")\n",
    "    \n",
    "    if not missing_columns and not extra_columns:\n",
    "        print(f\"   ‚úÖ Schema matches perfectly!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Schema has differences\")\n",
    "        return False\n",
    "\n",
    "# Verify schemas\n",
    "conv_bronze_schema_ok = verify_table_schema(conv_bronze_df, \"conv_vol\", \"bronze\")\n",
    "conv_silver_schema_ok = verify_table_schema(conv_silver_df, \"conv_vol\", \"silver\")\n",
    "\n",
    "ngl_bronze_schema_ok = verify_table_schema(ngl_bronze_df, \"ngl_vol\", \"bronze\")\n",
    "ngl_silver_schema_ok = verify_table_schema(ngl_silver_df, \"ngl_vol\", \"silver\")\n",
    "\n",
    "print(f\"\\nüìã Schema Verification Summary:\")\n",
    "print(f\"   Conv Bronze: {'‚úÖ' if conv_bronze_schema_ok else '‚ùå'}\")\n",
    "print(f\"   Conv Silver: {'‚úÖ' if conv_silver_schema_ok else '‚ùå'}\")\n",
    "print(f\"   NGL Bronze: {'‚úÖ' if ngl_bronze_schema_ok else '‚ùå'}\")\n",
    "print(f\"   NGL Silver: {'‚úÖ' if ngl_silver_schema_ok else '‚ùå'}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 5: Data Quality Score Analysis\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 5: Data Quality Score Analysis\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def analyze_data_quality_scores(df, dataset_name):\n",
    "    \"\"\"Analyze data quality score distribution.\"\"\"\n",
    "    if df is None or \"_data_quality_score\" not in df.columns:\n",
    "        print(f\"   ‚ùå No data quality scores available for {dataset_name}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate quality score statistics\n",
    "    quality_stats = df.select(\"_data_quality_score\").describe().collect()\n",
    "    \n",
    "    print(f\"\\nüìà {dataset_name} Data Quality Score Distribution:\")\n",
    "    for stat in quality_stats:\n",
    "        metric = stat[\"summary\"]\n",
    "        value = stat[\"_data_quality_score\"]\n",
    "        if value and metric in [\"count\", \"mean\", \"min\", \"max\", \"stddev\"]:\n",
    "            if metric == \"count\":\n",
    "                print(f\"   Total rows: {value}\")\n",
    "            else:\n",
    "                print(f\"   {metric.capitalize()}: {float(value):.2f}\")\n",
    "    \n",
    "    # Count rows by quality bands\n",
    "    quality_bands = df.select(\n",
    "        count(when(col(\"_data_quality_score\") >= 95, 1)).alias(\"excellent\"),\n",
    "        count(when((col(\"_data_quality_score\") >= 85) & (col(\"_data_quality_score\") < 95), 1)).alias(\"good\"),\n",
    "        count(when((col(\"_data_quality_score\") >= 70) & (col(\"_data_quality_score\") < 85), 1)).alias(\"fair\"),\n",
    "        count(when(col(\"_data_quality_score\") < 70, 1)).alias(\"poor\"),\n",
    "        count(when(col(\"_data_quality_score\").isNull(), 1)).alias(\"no_score\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    total_rows = sum([quality_bands[band] for band in quality_bands.asDict().keys()])\n",
    "    \n",
    "    print(f\"   Quality Bands:\")\n",
    "    print(f\"      Excellent (‚â•95): {quality_bands['excellent']:,} ({quality_bands['excellent']/total_rows*100:.1f}%)\")\n",
    "    print(f\"      Good (85-94): {quality_bands['good']:,} ({quality_bands['good']/total_rows*100:.1f}%)\")\n",
    "    print(f\"      Fair (70-84): {quality_bands['fair']:,} ({quality_bands['fair']/total_rows*100:.1f}%)\")\n",
    "    print(f\"      Poor (<70): {quality_bands['poor']:,} ({quality_bands['poor']/total_rows*100:.1f}%)\")\n",
    "    print(f\"      No Score: {quality_bands['no_score']:,} ({quality_bands['no_score']/total_rows*100:.1f}%)\")\n",
    "\n",
    "# Analyze quality scores\n",
    "if conv_silver_df:\n",
    "    analyze_data_quality_scores(conv_silver_df, \"Conventional Volume\")\n",
    "\n",
    "if ngl_silver_df:\n",
    "    analyze_data_quality_scores(ngl_silver_df, \"NGL Volume\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 6: Prepare Data for Forecasting\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 6: Prepare Data for Forecasting\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Prepare NGL data for forecasting (this is what the forecasting module needs)\n",
    "if ngl_silver_df:\n",
    "    try:\n",
    "        forecast_ready_df = prepare_data_for_forecasting(\n",
    "            spark=spark,\n",
    "            config=config,\n",
    "            table_type=\"ngl_vol\",\n",
    "            quality_threshold=70.0  # Only include rows with quality score >= 70\n",
    "        )\n",
    "        \n",
    "        forecast_count = forecast_ready_df.count()\n",
    "        original_count = ngl_silver_df.count()\n",
    "        \n",
    "        print(f\"‚úÖ NGL Data prepared for forecasting:\")\n",
    "        print(f\"   Original rows: {original_count:,}\")\n",
    "        print(f\"   Forecast-ready rows: {forecast_count:,}\")\n",
    "        print(f\"   Quality filtered out: {original_count - forecast_count:,} rows\")\n",
    "        \n",
    "        # Show sample of forecast-ready data\n",
    "        print(f\"\\nüìã Sample of forecast-ready data:\")\n",
    "        sample_df = forecast_ready_df.select(\n",
    "            \"WellID\", \"ProductionMonth\", \"OperatorName\", \n",
    "            \"GasProduction\", \"OilProduction\", \"CondensateProduction\",\n",
    "            \"_data_quality_score\"\n",
    "        ).limit(5)\n",
    "        \n",
    "        sample_df.show(truncate=False)\n",
    "        \n",
    "        print(f\"‚úÖ Data is now ready for forecasting workflows!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error preparing data for forecasting: {e}\")\n",
    "        forecast_ready_df = None\n",
    "else:\n",
    "    print(\"‚ùå No NGL silver data available for forecasting preparation\")\n",
    "    forecast_ready_df = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 7: Generate Comprehensive Processing Report\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üìä STEP 7: Processing Summary Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def generate_processing_summary():\n",
    "    \"\"\"Generate a comprehensive summary of the processing pipeline.\"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        \"timestamp\": \"2024-01-01T00:00:00\",  # This would be current timestamp in real execution\n",
    "        \"pipeline_status\": \"COMPLETED\",\n",
    "        \"datasets_processed\": 0,\n",
    "        \"total_errors\": 0,\n",
    "        \"total_warnings\": 0,\n",
    "        \"tables_created\": [],\n",
    "        \"data_quality_overview\": {}\n",
    "    }\n",
    "    \n",
    "    # Process conventional volume results\n",
    "    if conv_report:\n",
    "        summary[\"datasets_processed\"] += 1\n",
    "        if conv_report.get('validation_report'):\n",
    "            val_report = conv_report['validation_report']\n",
    "            summary[\"total_errors\"] += len(val_report.get('validation_errors', []))\n",
    "            summary[\"total_warnings\"] += len(val_report.get('validation_warnings', []))\n",
    "        \n",
    "        summary[\"tables_created\"].extend([\n",
    "            conv_report.get('bronze_table', 'N/A'),\n",
    "            conv_report.get('silver_table', 'N/A')\n",
    "        ])\n",
    "        \n",
    "        summary[\"data_quality_overview\"][\"conventional\"] = conv_report.get('data_quality_summary', {})\n",
    "    \n",
    "    # Process NGL volume results\n",
    "    if ngl_report:\n",
    "        summary[\"datasets_processed\"] += 1\n",
    "        if ngl_report.get('validation_report'):\n",
    "            val_report = ngl_report['validation_report']\n",
    "            summary[\"total_errors\"] += len(val_report.get('validation_errors', []))\n",
    "            summary[\"total_warnings\"] += len(val_report.get('validation_warnings', []))\n",
    "        \n",
    "        summary[\"tables_created\"].extend([\n",
    "            ngl_report.get('bronze_table', 'N/A'),\n",
    "            ngl_report.get('silver_table', 'N/A')\n",
    "        ])\n",
    "        \n",
    "        summary[\"data_quality_overview\"][\"ngl\"] = ngl_report.get('data_quality_summary', {})\n",
    "    \n",
    "    # Determine overall status\n",
    "    if summary[\"total_errors\"] > 0:\n",
    "        summary[\"pipeline_status\"] = \"COMPLETED_WITH_ERRORS\"\n",
    "    elif summary[\"total_warnings\"] > 0:\n",
    "        summary[\"pipeline_status\"] = \"COMPLETED_WITH_WARNINGS\"\n",
    "    else:\n",
    "        summary[\"pipeline_status\"] = \"SUCCESS\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Generate and display summary\n",
    "processing_summary = generate_processing_summary()\n",
    "\n",
    "print(f\"üéØ PROCESSING PIPELINE SUMMARY\")\n",
    "print(f\"Status: {processing_summary['pipeline_status']}\")\n",
    "print(f\"Datasets Processed: {processing_summary['datasets_processed']}\")\n",
    "print(f\"Total Validation Errors: {processing_summary['total_errors']}\")\n",
    "print(f\"Total Validation Warnings: {processing_summary['total_warnings']}\")\n",
    "\n",
    "print(f\"\\nüìã Tables Created:\")\n",
    "for table in processing_summary['tables_created']:\n",
    "    print(f\"   ‚Ä¢ {table}\")\n",
    "\n",
    "print(f\"\\nüìä Data Quality Overview:\")\n",
    "for dataset, quality_info in processing_summary['data_quality_overview'].items():\n",
    "    if quality_info:\n",
    "        print(f\"   {dataset.upper()}:\")\n",
    "        print(f\"      Rows: {quality_info.get('total_rows', 0):,}\")\n",
    "        print(f\"      Quality: {quality_info.get('quality_assessment', 'N/A')}\")\n",
    "        print(f\"      Avg Score: {quality_info.get('average_quality_score', 0):.1f}\")\n",
    "\n",
    "print(f\"\\nüèÅ Processing pipeline complete!\")\n",
    "if forecast_ready_df:\n",
    "    print(f\"‚úÖ Data is ready for forecasting workflows\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Check processing results before proceeding to forecasting\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "This processing pipeline has created:\n",
    "\n",
    "1. **Bronze Tables**: Raw data with proper schemas and basic cleaning\n",
    "   - `{catalog}.{schema}.conv_vol_bronze`\n",
    "   - `{catalog}.{schema}.ngl_vol_bronze`\n",
    "\n",
    "2. **Silver Tables**: Enhanced data with validation metadata and quality scores\n",
    "   - `{catalog}.{schema}.conv_vol_silver`\n",
    "   - `{catalog}.{schema}.ngl_vol_silver`\n",
    "\n",
    "3. **Forecast-Ready Data**: Quality-filtered data ready for forecasting workflows\n",
    "\n",
    "### For Forecasting Workflows:\n",
    "\n",
    "The data is now properly processed and validated. Use the silver tables or the forecast-ready data for:\n",
    "\n",
    "- **03_forecast.ipynb**: ARPS decline curve forecasting\n",
    "- **Streamlit applications**: Interactive forecasting and visualization\n",
    "- **Additional analytics**: Any downstream analysis requiring clean, validated data\n",
    "\n",
    "### Data Quality Monitoring:\n",
    "\n",
    "- Check `_data_quality_score` column in silver tables\n",
    "- Review validation errors/warnings for data source issues\n",
    "- Use quality scores to filter data for critical analyses\n",
    "\n",
    "### Schema Information:\n",
    "\n",
    "- All tables follow consistent, well-defined schemas\n",
    "- Validation rules are enforced at processing time\n",
    "- Metadata columns track data lineage and quality\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
